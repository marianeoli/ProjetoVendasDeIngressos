# üé´ Bilheteria.io - Sistema Distribu√≠do de Venda de Ingressos

> Projeto final da disciplina de Sistemas Distribu√≠dos.

O **Bilheteria.io** √© uma plataforma escal√°vel para venda de ingressos de alta demanda. O sistema foi projetado para lidar com picos de tr√°fego, garantindo integridade de estoque (sem *overselling*) e alta disponibilidade atrav√©s de uma arquitetura baseada em microsservi√ßos, mensageria ass√≠ncrona e banco de dados distribu√≠do (Sharded Cluster).

---

## üöÄ Principais Funcionalidades

### Para o Usu√°rio
* **Compra em Tempo Real:** Visualiza√ß√£o de eventos e setores (Pista, VIP, Camarote).
* **Reserva At√¥mica:** O sistema garante que, se voc√™ clicar em "Comprar", o ingresso √© reservado instantaneamente, impedindo que outro usu√°rio compre o mesmo assento no mesmo milissegundo.
* **M√∫ltiplas Categorias:** Suporte a diferentes setores e pre√ßos (Inteira/Meia) no mesmo evento.
* **Feedback Visual:** Interface reativa com SweetAlert2 para notifica√ß√µes de sucesso/erro.

### Para o Administrador
* **Dashboard Financeiro:** Acompanhamento em tempo real de vendas e receita.
* **Gest√£o de Eventos:** CRUD completo (Criar, Editar, Pausar, Excluir) com suporte a m√∫ltiplos lotes/setores.
* **Controle de Concorr√™ncia:** Visualiza√ß√£o do estoque real distribu√≠do entre os shards.

---

## üèóÔ∏è Arquitetura do Sistema

O sistema resolve o problema de **concorr√™ncia em vendas de ingressos** utilizando as seguintes estrat√©gias:

1.  **API Gateway (FastAPI):** Recebe as requisi√ß√µes, valida tokens JWT e gerencia a l√≥gica de neg√≥cio.
2.  **Reserva At√¥mica (MongoDB):** Utiliza opera√ß√µes `find_one_and_update` com filtros de consist√™ncia para garantir decremento seguro do estoque antes de processar o pagamento.
3.  **Processamento Ass√≠ncrono (RabbitMQ):** Ap√≥s a reserva, o pedido √© enviado para uma fila de mensagens, desacoplando a resposta ao usu√°rio do processamento pesado (e-mail, confirma√ß√£o financeira).
4.  **Banco de Dados Distribu√≠do (MongoDB Sharded):**
    * **Sharding:** Os dados de vendas s√£o particionados (sharded) com base no `usuario_id`, permitindo que a carga de escrita e leitura seja distribu√≠da entre m√∫ltiplos servidores.
    * **Replication:** Cada shard possui r√©plicas para toler√¢ncia a falhas.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Backend:** Python 3.11, FastAPI, Uvicorn.
* **Frontend:** HTML5, JavaScript (ES6), TailwindCSS, SweetAlert2.
* **Banco de Dados:** MongoDB 7.0 (Configurado em Cluster Sharded).
* **Mensageria:** RabbitMQ.
* **Infraestrutura:** Docker, Docker Compose, AWS EC2.

---

## üíª Como Rodar Localmente (Docker)

Para testes r√°pidos e desenvolvimento, utilizamos o Docker Compose que sobe toda a stack (API, Rabbit, Mongo Single, Worker) automaticamente.

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/marianeoli/ProjetoVendasDeIngressos.git](https://github.com/marianeoli/ProjetoVendasDeIngressos.git)
    cd projeto-venda-ingressos
    ```

2.  **Suba os containers:**
    ```bash
    docker compose up --build
    ```

3.  **Acesse a aplica√ß√£o:**
    * Frontend: `http://localhost:8000`
    * Documenta√ß√£o API (Swagger): `http://localhost:8000/docs`
    * RabbitMQ Manager: `http://localhost:15672` (User: guest / Pass: guest)

4.  **Popular Banco (Opcional):**
    Para criar eventos de teste automaticamente:
    ```bash
    python popula_banco.py
    ```

---

## ‚òÅÔ∏è Implanta√ß√£o do Cluster MongoDB (AWS)

Para o ambiente de produ√ß√£o distribu√≠do, configuramos um cluster manual em inst√¢ncias EC2 **t3.small** (Debian).

### Topologia do Cluster
* **Config Server:** Gerencia os metadados do cluster.
* **Shard 1 & Shard 2:** Armazenam os fragmentos de dados.
* **Mongos (Router):** Roteia as consultas da aplica√ß√£o para o shard correto.

### Configura√ß√£o de Rede e Hosts
Portas liberadas no Security Group: `27017` a `27020`.
Adicione os IPs privados no `/etc/hosts` de todas as m√°quinas:

```text
<IP_PRIVADO_CONFIG>  configdb
<IP_PRIVADO_SHARD1>  shard1
<IP_PRIVADO_SHARD2>  shard2
<IP_PRIVADO_MONGOS>  mongos
```

## Como Rodar o Banco  

Em cada inst√¢ncia respectiva, execute os scripts de inicializa√ß√£o contidos na pasta ./MongoCluster:  
**No Config Server:**  
```text
chmod +x ./MongoCluster/config-init.sh  
./MongoCluster/config-init.sh
```

**No Shards 1:**
```text
chmod +x ./MongoCluster/shard1-init.sh  
./MongoCluster/shard1-init.sh
```

**No Shards 2:**
```text
chmod +x ./MongoCluster/shard2-init.sh  
./shard2-init.sh
```

**No Mongos Roteador:** O Mongos deve ser o √∫ltimo a subir, pois ele depende que os shards e o config server j√° estejam ativos.
```text 
chmod +x ./MongoCluster/mongos-init.sh  
./MongoCluster/mongos-init.sh
```

### Sobre os Arquivos de Configura√ß√£o
* .conf - Arquivos de configura√ß√£o do MongoDBDefine portas, caminhos de dados e pap√©is (sharding/replSetName).  
* .service - Unidades do SystemdPermite gerenciar o banco via systemctl (start/stop/enable).  
* -init.sh - Scripts de automa√ß√£o para instalar o MongoDB 7.0 e inicializa os Replica Sets.

## Comandos √öteis de Gerenciamento  
**Verificar o status dos servi√ßos:** 
```text
sudo systemctl status config # No config  
sudo systemctl status shard1 # Nos Shards  
sudo systemctl status mongos # No Mongos
```

**Verificar a sa√∫de do cluster (pelo Mongos):**  
Conecte-se ao Mongos e rode sh.status() // Mostra os shards ativos e a distribui√ß√£o dos bancos

**Verificar logs em caso de erro:**  
```text
sudo journalctl -u config -f
```

## Sempre que reiniciar as inst√¢ncias, dar o comando:  
```text
sudo systemctl start config # No config  
sudo systemctl start shard1 # No shard1  
sudo systemctl start shard2 # No shard2  
sudo systemctl start mongos # No mongos, DEVE SER O √öLTIMO A SER STARTADO
```

## Conex√£o
Para ter a aplica√ß√£o e banco conectados, adicione o ip p√∫blico do servidor mongos no arquivo /etc/hosts da m√°quina que est√£o os arquivos da aplica√ß√£o:  
**sudo nano /etc/hosts**  
### Adicione:  
```text
<IP_P√öBLICO_MONGOS> mongos 
```

---

## üë• Autores
Mariane Silva e Milena Mota 